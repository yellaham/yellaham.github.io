---
title: "Deep Gaussian Mixture Ensembles"
collection: publications
permalink: /publication/2023-07-02-deep-gaussian-mixture-ensembles
date: 2023-07-02
venue: 'Uncertainty in Artificial Intelligence'
paperurl: 'http://yellaham.github.io/files/2023-07-02-deep-gaussian-mixture-ensembles.pdf'
authors: 'Yousef El-Laham, Niccol√≤ Dalmasso, Elizabeth Fons, Svitlana Vyetrenko'
pages: '549-559'
year: 2023
publisher: 'PMLR'
---

<details>
<summary>Abstract</summary>
<br>
This work introduces a novel probabilistic deep learning technique called deep Gaussian mixture ensembles (DGMEs),
which enables accurate quantification of both epistemic and aleatoric uncertainty. By assuming the data generating 
process follows that of a Gaussian mixture, DGMEs are capable of approximating complex probability distributions, 
such as heavy-tailed or multimodal distributions. Our contributions include the derivation of an 
expectation-maximization (EM) algorithm used for learning the model parameters, which results in an upper-bound on the 
log-likelihood of training data over that of standard deep ensembles. Additionally, the proposed EM training procedure 
allows for learning of mixture weights, which is not commonly done in ensembles. Our experimental results demonstrate 
that DGMEs outperform state-of-the-art uncertainty quantifying deep learning models in handling complex predictive 
densities.
</details>

[Link to paper](http://yellaham.github.io/files/2023-07-02-deep-gaussian-mixture-ensembles.pdf)
