---
title: "Styletime: Style Transfer for Synthetic Time Series Generation"
collection: publications
permalink: /publication/2022-11-02-styletime-style-transfer-time-series
paperurl: 'http://yellaham.github.io/files/2022-11-02-styletime-style-transfer-time-series.pdf'
date: 2022-11-02
venue: 'Proceedings of the Third ACM International Conference on AI in Finance'
authors: '<b>Yousef El-Laham</b>, Svitlana Vyetrenko'
pages: '489-496'
year: 2022
---

<details>
<summary>Description</summary>
<br>
Neural style transfer is a powerful computer vision technique that can incorporate the artistic "style" of one image 
to the "content" of another. The underlying theory behind the approach relies on the assumption that the style of an 
image is represented by the Gram matrix of its features, which is typically extracted from pretrained convolutional 
neural networks (e.g., VGG-19). This idea does not straightforwardly extend to time series stylization since notions 
of style for two-dimensional images are not analogous to notions of style for one-dimensional time series. In this 
work, a novel formulation of time series style transfer is proposed for the purpose of synthetic data generation and 
enhancement. We introduce the concept of stylized features for time series, which is directly related to the time 
series realism properties, and propose a novel stylization algorithm, called StyleTime, that uses explicit feature 
extraction techniques to combine the underlying content (trend) of one time series with the style (distributional 
properties) of another. Further, we discuss evaluation metrics, and compare our work to existing state-of-the-art time 
series generation and augmentation schemes. To validate the effectiveness of our methods, we use stylized synthetic 
data as a means for data augmentation to improve the performance of recurrent neural network models on several 
forecasting tasks.
</details>

[Link to paper](http://yellaham.github.io/files/2022-11-02-styletime-style-transfer-time-series.pdf)